{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Model development automation using pipelines\n",
    "\n",
    "In this notebook we just focus on developing pipelines and automating the intila model development process. We automate the generic steps as much as possible, and keep the work as generic as possible, so that this pipeline can be used for all the projects.\n",
    "\n",
    "We use California housing dataset for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer, MinMaxScaler\n",
    "from sklearn.pipeline import FeatureUnion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations\n",
    "\n",
    "For any data science project, we need to perform the following common transformations:\n",
    "\n",
    "* Impute the missing values of numeric columns with median/mean/most frequent values\n",
    "* One hot encoding of the character variables\n",
    "* Select the columns of the data frame, and return as a numpy array\n",
    "\n",
    "## Model development\n",
    "\n",
    "We want to develop as many models as possible (perhaps with their default hyper parms), and select top 3 models for further study. So we will also try to automate the initial phase of the model development wherever possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and splitting the data into test and training datasets\n",
    "\n",
    "In the following code I stratified median_income categories, but you do need to do this, and may ignore that step, as our focus is to develop a generic transformation pipeline. Just focus on how we are splitting the data into test and training data (20:80). The housing_train and housing_test data frames contain the training and test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: \n",
      " 3.0    0.350594\n",
      "2.0    0.318859\n",
      "4.0    0.176296\n",
      "5.0    0.114402\n",
      "1.0    0.039850\n",
      "Name: income_cat, dtype: float64\n",
      "Test data: \n",
      " 3.0    0.350533\n",
      "2.0    0.318798\n",
      "4.0    0.176357\n",
      "5.0    0.114583\n",
      "1.0    0.039729\n",
      "Name: income_cat, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Reading the data to a data frame\n",
    "housing=pd.read_csv(\"datasets/housing/housing.csv\")\n",
    "\n",
    "#The income_cat variable helps us to stratify the data equally in both the test and training\n",
    "#As per the text book the median_income variable is very important\n",
    "#We want to make sure that this variable will have approximately equal distribution in both test and train data\n",
    "#Since it is a continuous variable, we will divide the variable's values into 5 intervals\n",
    "#and use the resulting categories to stratify the sampling process.\n",
    "\n",
    "housing[\"income_cat\"]=np.ceil(housing[\"median_income\"]/1.5)\n",
    "\n",
    "#Change all the salary category to 5, if the above column has any sal of greater than 5\n",
    "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0,inplace=True)\n",
    "\n",
    "#This will remove the new column from the data frame\n",
    "y = housing.pop(\"income_cat\")\n",
    "X = housing\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Train data: \\n {}\".format(y_train.value_counts()/len(y_train)))\n",
    "print(\"Test data: \\n {}\".format(y_test.value_counts()/len(y_test)))\n",
    "\n",
    "#Name the test data as housing_test and train data as housing_train data frames\n",
    "housing_train = X_train\n",
    "housing_test  = X_test\n",
    "\n",
    "#You can ignore the income category, since the split is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train_label = housing_train.pop('median_house_value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation pipelines\n",
    "The following code block builds the required pipelines to perform these transformations. \n",
    "In summary we will perform the following transformations:\n",
    "1. Create a new variable representing the average number of people per house\n",
    "2. Create a new variable representing the average number of rooms per house\n",
    "3. Create a new variable representing the average number of bedrooms per room (we are skeptical if this helps in our model)\n",
    "4. Substitute the missing values in total_bedrooms variable with the median value of total_bedrooms. But we also want to try substituting the missing values with most frequent value and also with average value. \n",
    "5. Scale all the numeric values with standard scaler. Another alternative is min-max scaler. We want to try both and pick the best\n",
    "6. One-hot encode the categorical variable ocean_proximity\n",
    "\n",
    "Follow the comments embedded in the code for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n",
      "ocean_proximity\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 493300.7,  220740. ,  214250. , ...,  257910. ,  152560. ,  101860. ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer, MinMaxScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "##Get the column numbers of the columns of interest\n",
    "#rooms_ix, bedrooms_ix, population_ix, household_ix = 3,4,5,6\n",
    "\n",
    "#Get the names of all the numeric and categorical columns\n",
    "\n",
    "all_columns = list(housing) #Will get the column names as a list\n",
    "numeric_columns = all_columns[:-2]\n",
    "categorical_columns = all_columns[-1]\n",
    "print(numeric_columns)\n",
    "print(categorical_columns)\n",
    "\n",
    "\n",
    "##To build any custom transformer, you have to use BaseEstimator and TransformerMixin as base classes\n",
    "##The transformer must define fit() and transform() functions\n",
    "##The following transformer will create three additional variables. Since we are developing a generic pipeline,\n",
    "##I commented the following transformer. But it acts as an example of the way we can develop custom variables\n",
    "##to be added to the data frame.\n",
    "#class CombinedAttributesAddr(BaseEstimator, TransformerMixin):\n",
    "#    def __init__(self, add_bedrooms_per_room=True): #NO *args or **kargs\n",
    "#        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "#    \n",
    "#    def fit(self, X, y=None):\n",
    "#        return self #Nothing else to do\n",
    "#    \n",
    "#    def transform(self, X, y=None):\n",
    "#        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "#        population_per_household = X[:,population_ix] / X[:,household_ix]\n",
    "#        \n",
    "#        if self.add_bedrooms_per_room:\n",
    "#            bedrooms_per_room = X[:,bedrooms_ix] / X[:,rooms_ix]\n",
    "#            #np.c_ will concatenate the new columns to the matrix X\n",
    "#            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "#        else:\n",
    "#            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "#This will help us to select the desired columns of a data frame\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self,X, y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "class MultiLabelTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    #def __init__(self):\n",
    "        #__init__ def not needed\n",
    "        #self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.lb = LabelBinarizer()\n",
    "        self.lb.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.lb.transform(X)\n",
    "\n",
    "    \n",
    "    \n",
    "class ImputerTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self,imputer_type=\"median\",missing_values='NaN'):\n",
    "        self.imputer_type = imputer_type\n",
    "        self.missing_values = missing_values\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.imputer_type == \"median\":\n",
    "            self.imputer = Imputer(missing_values = self.missing_values, strategy=\"median\")\n",
    "            self.imputer.fit(X)\n",
    "        elif self.imputer_type == \"mean\":\n",
    "            self.imputer = Imputer(missing_values = self.missing_values, strategy=\"mean\")\n",
    "            self.imputer.fit(X)\n",
    "        else: \n",
    "            self.imputer = Imputer(missing_values = self.missing_values, strategy=\"most_frequent\")\n",
    "            self.imputer.fit(X)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.imputer.transform(X)\n",
    "    \n",
    "    \n",
    "class ScalerTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self,scaler_type=\"std\"):\n",
    "        self.scaler_type = scaler_type\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.scaler_type == \"std\":\n",
    "            self.scaler = StandardScaler()\n",
    "            self.scaler.fit(X)\n",
    "        else:\n",
    "            self.scaler = MinMaxScaler()\n",
    "            self.scaler.fit(X)\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.scaler.transform(X)\n",
    "    \n",
    "    \n",
    "    \n",
    "num_pipeline = Pipeline([ \\\n",
    "                         ('selector',DataFrameSelector(numeric_columns)), \\\n",
    "                         ('imputer', Imputer(strategy=\"median\")), \\\n",
    "                         ('scaler',ScalerTransformer(scaler_type=\"std\")) \\\n",
    "                        ])\n",
    "\n",
    "cat_pipeline = Pipeline([ \\\n",
    "                         ('selector',DataFrameSelector(categorical_columns)), \\\n",
    "                         ('label_binarizer', MultiLabelTransformer()) \\\n",
    "                        ])\n",
    "\n",
    "#Combine the numeric and categorical transformations into a single numpy matrix\n",
    "#The num_pipeline and cat_pipeline are evaluated independently and parallely. The results are combined at the end.\n",
    "full_transform_pipeline = FeatureUnion(transformer_list = [\n",
    "                                                 (\"num_pipeline\",num_pipeline),\n",
    "                                                 (\"cat_pipeline\",cat_pipeline)\n",
    "                                                ])\n",
    "\n",
    "#Let us fit a RandomForestRegressor on the training data, with default parameters\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Create another pipeline with estimator as the end transformer in the pipeline\n",
    "#Whenever a fit() is called on the pipeline, all the transformations in the pipeline, from left \n",
    "#are evaluated as follows:\n",
    "## 1. Call fit() followed by the transformation. Send the first transformation to the fit() of second transformation...\n",
    "## 2. If Feature Union is used, the individual components will be called in parallel.\n",
    "\n",
    "# If transform() is called on the pipeline, then\n",
    "## 1. Then the input data set is transformed using each transform() method of the components beginning from the left.\n",
    "## The transformations are made using the already computed fit() in the respective components. \n",
    "\n",
    "# If fit_transform() is called on the pipeline, then\n",
    "## 1. Then the input data set is fit() and then transformed() at each subsequent component. \n",
    "## For example if the final component is a LinearRegressor, then after all transformations, the fit() of the LinearRegressor\n",
    "## will estimate parms using the data from the immediate transformation, and the obtained model is applied again on the data\n",
    "## from the immediate transformation\n",
    "\n",
    "# If predict() is called on the pipeline, then\n",
    "## 1. Then the input data set is transformed using each transform() method of the components beginning from the left.\n",
    "## The transformations are made using the already computed fit() in the respective component. \n",
    "## The final component's transformation will use its already computed parms using the fit() to predict the values of the \n",
    "## input data set.\n",
    "\n",
    "predict_pipeline = Pipeline([(\"full_transform_pipeline\",full_transform_pipeline),(\"rf_reg\", RandomForestRegressor())])\n",
    "\n",
    "\n",
    "predict_pipeline.fit(housing_train,housing_train_label)\n",
    "\n",
    "predict_pipeline.predict(housing_test)\n",
    "#full_pipeline.fit_transform(housing)\n",
    "\n",
    "#rf_reg = RandomForestRegressor()\n",
    "#rf_reg.fit(housing_train_prepared,housing_train_label)\n",
    "#housing_train_predictions = rf_reg.predict(housing_train_prepared)\n",
    "#rf_mse = mean_squared_error(housing_train_label,housing_train_predictions)\n",
    "#rf_rmse = np.sqrt(rf_mse)\n",
    "#rf_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parm_grid = [{'rf_reg__n_estimators': [3,10,30],'rf_reg__max_features': [2,4,6,8], \\\n",
    "             'full_pipeline__num_pipeline__imputer__strategy':['mean','median','most_frequent']}, \\\n",
    "             {'rf_reg__bootstrap': [False],'rf_reg__n_estimators':[3,10],'rf_reg__max_features':[2,4]}]\n",
    "\n",
    "grid_search = GridSearchCV(predict_pipeline,parm_grid,cv=5,scoring='neg_mean_squared_error',verbose=2)\n",
    "grid_search.fit(housing_train,housing_train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=rf \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=rf, total=   0.9s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=rf \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=rf, total=   0.8s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=rf \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=rf, total=   0.8s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=rf \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=rf, total=   0.8s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=rf \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=rf, total=   0.8s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=dt, total=   0.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=dt, total=   0.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=dt, total=   0.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=dt, total=   0.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=dt, total=   0.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm, total=  12.2s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm, total=  11.7s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm, total=  12.4s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm, total=  11.7s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm, total=  11.7s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=rf \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=rf, total=   0.9s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=rf \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=rf, total=   0.8s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=rf \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=rf, total=   0.9s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=rf \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=rf, total=   0.9s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=rf \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=rf, total=   0.9s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt, total=   0.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt, total=   0.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt, total=   0.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt, total=   0.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt, total=   0.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm, total=  12.2s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm, total=  12.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm, total=  11.9s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm, total=  12.2s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm, total=  12.7s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf, total=   2.0s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf, total=   2.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf, total=   2.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf, total=   2.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf, total=   1.9s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt, total=   1.2s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt, total=   1.2s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt, total=   1.3s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt, total=   1.3s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt, total=   1.4s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=svm, total=  13.4s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=svm, total=  13.5s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=svm, total=  13.6s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=svm, total=  12.9s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=svm, total=  13.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('full_transform_pipeline', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('num_pipeline', Pipeline(steps=[('selector', DataFrameSelector(attribute_names=['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income'])), ('impute...())]))],\n",
       "       transformer_weights=None)), ('reg_algorithm', RegressionAlgorithm(algorithm='svm'))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'full_transform_pipeline__num_pipeline__imputer__strategy': ['mean', 'median', 'most_frequent'], 'reg_algorithm__algorithm': ['rf', 'dt', 'svm']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RegressionAlgorithm(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self,algorithm=\"rf\"):\n",
    "        self.algorithm = algorithm\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.algorithm == \"rf\":\n",
    "            self.model = RandomForestRegressor()\n",
    "\n",
    "        if self.algorithm == \"dt\":\n",
    "            from sklearn.tree import DecisionTreeRegressor\n",
    "            self.model = DecisionTreeRegressor()\n",
    "\n",
    "        if self.algorithm == \"svm\":\n",
    "            from sklearn.svm import SVR\n",
    "            self.model = SVR()\n",
    "            \n",
    "        self.model.fit(X,y)\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.model.transform(X)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "\n",
    "predict_pipeline = Pipeline([(\"full_transform_pipeline\",full_transform_pipeline),(\"reg_algorithm\", \\\n",
    "                                                                                  RegressionAlgorithm(algorithm=\"svm\"))])\n",
    "#predict_pipeline.fit(housing_train,housing_train_label)\n",
    "#predict_pipeline.predict(housing_test)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parm_grid = [{'full_transform_pipeline__num_pipeline__imputer__strategy':['mean','median','most_frequent'], \\\n",
    "             'reg_algorithm__algorithm':['rf','dt','svm']}]\n",
    "\n",
    "grid_search = GridSearchCV(predict_pipeline,parm_grid,cv=5,scoring='neg_mean_squared_error',verbose=2)\n",
    "grid_search.fit(housing_train,housing_train_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average CV scores\n",
    "Lesser the better. But the GridSearchCV takes a long time to train, so we will use RandomizedSearchCV also later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52695.3140001 {'full_transform_pipeline__num_pipeline__imputer__strategy': 'mean', 'reg_algorithm__algorithm': 'rf'}\n",
      "70630.8507698 {'full_transform_pipeline__num_pipeline__imputer__strategy': 'mean', 'reg_algorithm__algorithm': 'dt'}\n",
      "118631.523834 {'full_transform_pipeline__num_pipeline__imputer__strategy': 'mean', 'reg_algorithm__algorithm': 'svm'}\n",
      "52663.5306117 {'full_transform_pipeline__num_pipeline__imputer__strategy': 'median', 'reg_algorithm__algorithm': 'rf'}\n",
      "70092.4331838 {'full_transform_pipeline__num_pipeline__imputer__strategy': 'median', 'reg_algorithm__algorithm': 'dt'}\n",
      "118631.492999 {'full_transform_pipeline__num_pipeline__imputer__strategy': 'median', 'reg_algorithm__algorithm': 'svm'}\n",
      "52696.8223611 {'full_transform_pipeline__num_pipeline__imputer__strategy': 'most_frequent', 'reg_algorithm__algorithm': 'rf'}\n",
      "69694.1937892 {'full_transform_pipeline__num_pipeline__imputer__strategy': 'most_frequent', 'reg_algorithm__algorithm': 'dt'}\n",
      "118631.520934 {'full_transform_pipeline__num_pipeline__imputer__strategy': 'most_frequent', 'reg_algorithm__algorithm': 'svm'}\n"
     ]
    }
   ],
   "source": [
    "cvres=grid_search.cv_results_\n",
    "for mean_score,parms in zip(cvres[\"mean_test_score\"],cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score),parms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the n_iter parm properly. The following code also ran for a while. The n_iter parm must be less than the number of parm combinations (9 in the following example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf, total=   2.0s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf, total=   2.0s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf, total=   2.0s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf, total=   2.0s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=rf, total=   2.0s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt, total=   1.3s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt, total=   1.3s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt, total=   1.3s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt, total=   1.2s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=most_frequent, reg_algorithm__algorithm=dt, total=   1.2s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt, total=   0.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt, total=   0.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt, total=   0.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt, total=   0.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=dt, total=   0.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm, total=  12.5s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm, total=  12.3s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm, total=  12.3s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm, total=  12.2s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=median, reg_algorithm__algorithm=svm, total=  12.8s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm, total=  12.1s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm, total=  11.8s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm, total=  11.6s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm, total=  12.2s\n",
      "[CV] full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm \n",
      "[CV]  full_transform_pipeline__num_pipeline__imputer__strategy=mean, reg_algorithm__algorithm=svm, total=  12.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=Pipeline(steps=[('full_transform_pipeline', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('num_pipeline', Pipeline(steps=[('selector', DataFrameSelector(attribute_names=['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income'])), ('impute...())]))],\n",
       "       transformer_weights=None)), ('reg_algorithm', RegressionAlgorithm(algorithm='svm'))]),\n",
       "          fit_params={}, iid=True, n_iter=5, n_jobs=1,\n",
       "          param_distributions={'full_transform_pipeline__num_pipeline__imputer__strategy': ['mean', 'median', 'most_frequent'], 'reg_algorithm__algorithm': ['rf', 'dt', 'svm']},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring='neg_mean_squared_error',\n",
       "          verbose=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parm_grid = {'full_transform_pipeline__num_pipeline__imputer__strategy':['mean','median','most_frequent'], \\\n",
    "             'reg_algorithm__algorithm':['rf','dt','svm']}\n",
    "\n",
    "grid_search = RandomizedSearchCV(predict_pipeline,param_distributions=parm_grid, n_iter=5, cv=5, scoring='neg_mean_squared_error', \\\n",
    "                                verbose=2)\n",
    "grid_search.fit(housing_train,housing_train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52563.5443189 {'full_transform_pipeline__num_pipeline__imputer__strategy': 'most_frequent', 'reg_algorithm__algorithm': 'rf'}\n",
      "69933.5660174 {'full_transform_pipeline__num_pipeline__imputer__strategy': 'most_frequent', 'reg_algorithm__algorithm': 'dt'}\n",
      "69684.3699458 {'full_transform_pipeline__num_pipeline__imputer__strategy': 'median', 'reg_algorithm__algorithm': 'dt'}\n",
      "118631.492999 {'full_transform_pipeline__num_pipeline__imputer__strategy': 'median', 'reg_algorithm__algorithm': 'svm'}\n",
      "118631.523834 {'full_transform_pipeline__num_pipeline__imputer__strategy': 'mean', 'reg_algorithm__algorithm': 'svm'}\n"
     ]
    }
   ],
   "source": [
    "cvres=grid_search.cv_results_\n",
    "for mean_score,parms in zip(cvres[\"mean_test_score\"],cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score),parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
